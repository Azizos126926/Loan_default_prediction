{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c147a5-441a-42fe-b77a-4ef632fb7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load training data\n",
    "X_train = pd.read_csv(\"../data/train/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../data/train/y_train.csv\")\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv(\"../data/test/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../data/test/y_test.csv\")\n",
    "\n",
    "# If y_train/y_test is stored as a DataFrame, convert to Series\n",
    "y_train = y_train.squeeze()  \n",
    "y_test = y_test.squeeze()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bdb763-f6d5-4c9d-a2e9-6d9a1b83f953",
   "metadata": {},
   "source": [
    "# Training \n",
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c48da09-5c05-4e6a-974c-dad6b79fdd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     45139\n",
      "           1       0.61      0.03      0.06      5931\n",
      "\n",
      "    accuracy                           0.89     51070\n",
      "   macro avg       0.75      0.52      0.50     51070\n",
      "weighted avg       0.85      0.89      0.84     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde9182c-2d78-4624-aa2a-8cdb124afe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: Counter({0: 180555, 1: 180555})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_train_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee542351-a369-4ed3-8420-d49295a8fd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after undersampling: Counter({0: 23722, 1: 23722})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Initialize undersampler\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply undersampling\n",
    "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"Class distribution after undersampling:\", Counter(y_train_under))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec143e1-91e9-4ff1-8a9c-26f8ae304b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.79     45139\n",
      "           1       0.22      0.70      0.33      5931\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.73     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Predictions\n",
    "y_pred_under = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_under = accuracy_score(y_test, y_pred_under)\n",
    "print(f\"Accuracy: {accuracy_under:.4f}\")\n",
    "print(classification_report(y_test, y_pred_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c64b4376-e2bd-4a80-9194-ab5f8ff065cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6840\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.68      0.79     45139\n",
      "           1       0.22      0.69      0.34      5931\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.57     51070\n",
      "weighted avg       0.86      0.68      0.74     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions\n",
    "y_pred_smote = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy_smote = accuracy_score(y_test, y_pred_smote)\n",
    "print(f\"Accuracy: {accuracy_smote:.4f}\")\n",
    "print(classification_report(y_test, y_pred_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c686b60-9c55-4bc6-98a4-2eacdbbd2f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.79     45139\n",
      "           1       0.22      0.70      0.33      5931\n",
      "\n",
      "    accuracy                           0.68     51070\n",
      "   macro avg       0.58      0.69      0.56     51070\n",
      "weighted avg       0.86      0.68      0.73     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train model with balanced class weights\n",
    "clf = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526142b3-85ab-4965-970f-c12413449cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.73      0.82     45139\n",
      "           1       0.23      0.63      0.34      5931\n",
      "\n",
      "    accuracy                           0.72     51070\n",
      "   macro avg       0.59      0.68      0.58     51070\n",
      "weighted avg       0.86      0.72      0.76     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]), random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0058de3-c055-4932-8182-5cfc6d1c9185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.79     45139\n",
      "           1       0.22      0.68      0.33      5931\n",
      "\n",
      "    accuracy                           0.67     51070\n",
      "   macro avg       0.58      0.68      0.56     51070\n",
      "weighted avg       0.86      0.67      0.73     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=len(y_train_under[y_train_under == 0]) / len(y_train_under[y_train_under == 1]), random_state=42)\n",
    "xgb.fit(X_train_under, y_train_under)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97464f62-4a72-4ebd-8a05-69ff07aceb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     45139\n",
      "           1       0.54      0.09      0.15      5931\n",
      "\n",
      "    accuracy                           0.89     51070\n",
      "   macro avg       0.72      0.54      0.55     51070\n",
      "weighted avg       0.85      0.89      0.85     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=len(y_train_smote[y_train_smote == 0]) / len(y_train_smote[y_train_smote == 1]), random_state=42)\n",
    "xgb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cab2ce8-fcdc-44da-a9d9-7a8e92c4c7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azizk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:21:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200, 'scale_pos_weight': 1}\n",
      "Accuracy: 0.8849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     45139\n",
      "           1       0.53      0.09      0.15      5931\n",
      "\n",
      "    accuracy                           0.88     51070\n",
      "   macro avg       0.71      0.54      0.54     51070\n",
      "weighted avg       0.85      0.88      0.85     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [ 0.1, 0.2],\n",
    "    'n_estimators': [100, 200],\n",
    "    'scale_pos_weight': [ 1,5, 10]  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "# Initialize classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring='f1', cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Train the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7967648d-87d9-4e20-9417-a1c12ced9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88     45139\n",
      "           1       0.29      0.53      0.37      5931\n",
      "\n",
      "    accuracy                           0.79     51070\n",
      "   macro avg       0.61      0.68      0.63     51070\n",
      "weighted avg       0.86      0.79      0.82     51070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b973b2fc-c755-4d9f-a6ff-5a9d1e357348",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[0;32m     17\u001b[0m grid_search_rf \u001b[38;5;241m=\u001b[39m GridSearchCV(rf, param_grid_rf, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m grid_search_rf\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Get best model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m grid_search_rf\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [2, 5],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, scoring='f1', cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "431bd708-723b-4826-ac7e-ddbcc4da7f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Info] Number of positive: 23722, number of negative: 180555\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1327\n",
      "[LightGBM] [Info] Number of data points in the train set: 204277, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116127 -> initscore=-2.029633\n",
      "[LightGBM] [Info] Start training from score -2.029633\n",
      "Accuracy: 0.8839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     45139\n",
      "           1       0.50      0.09      0.15      5931\n",
      "\n",
      "    accuracy                           0.88     51070\n",
      "   macro avg       0.70      0.54      0.54     51070\n",
      "weighted avg       0.85      0.88      0.85     51070\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azizk\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_lgbm = {\n",
    "    'num_leaves': [100],\n",
    "    'learning_rate': [0.2],\n",
    "    'n_estimators': [200]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "lgbm = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search_lgbm = GridSearchCV(lgbm, param_grid_lgbm, scoring='f1', cv=5, verbose=2, n_jobs=-1)\n",
    "grid_search_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_lgbm = grid_search_lgbm.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "y_pred_lgbm = best_lgbm.predict(X_test)\n",
    "# Evaluate model\n",
    "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "print(f\"Accuracy: {accuracy_lgbm:.4f}\")\n",
    "print(classification_report(y_test, y_pred_lgbm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a198d24-5657-48c5-9c04-60e9bd931d8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, auto_class_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalanced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=500, depth=6, learning_rate=0.05, auto_class_weights='Balanced')\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b6d7e4-52de-4fb0-a6c8-039600384cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StackingClassifier\n\u001b[0;32m      2\u001b[0m final_model \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[1;32m----> 3\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mxgb\u001b[49m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, rf)],\n\u001b[0;32m      4\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mLogisticRegression()\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m final_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "final_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb), ('rf', rf)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34afe30-5145-483b-a417-f508af9bd20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
